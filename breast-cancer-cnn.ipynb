{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/joshuaampofoyentumi/breast-cancer-cnn?scriptVersionId=144582093\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading the Data","metadata":{}},{"cell_type":"code","source":"# import libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_meta = pd.read_csv('/kaggle/input/cbis-ddsm-breast-cancer-image-dataset/csv/meta.csv')\ndf_meta.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load dicom info file\ndf_dicom = pd.read_csv('/kaggle/input/cbis-ddsm-breast-cancer-image-dataset/csv/dicom_info.csv')\ndf_dicom.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check image types in dataset\ndf_dicom.SeriesDescription.unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check image path in dataset\n# cropped images\ncropped_images = df_dicom[df_dicom.SeriesDescription=='cropped images'].image_path\n#cropped_images.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#full mammogram images\nfull_mammo = df_dicom[df_dicom.SeriesDescription=='full mammogram images'].image_path\n#full_mammo.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ROI images\nroi_img = df_dicom[df_dicom.SeriesDescription=='ROI mask images'].image_path\n#roi_img.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# set correct image path for image types\nimdir = '../input/cbis-ddsm-breast-cancer-image-dataset/jpeg'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# change directory path of images\ncropped_images = cropped_images.replace('CBIS-DDSM/jpeg', imdir, regex=True)\nfull_mammo = full_mammo.replace('CBIS-DDSM/jpeg', imdir, regex=True)\nroi_img = roi_img.replace('CBIS-DDSM/jpeg', imdir, regex=True)\n\n# view new paths\nprint('Cropped Images paths:\\n')\nprint(cropped_images.iloc[0])\nprint('Full mammo Images paths:\\n')\nprint(full_mammo.iloc[0])\nprint('ROI Mask Images paths:\\n')\nprint(roi_img.iloc[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# organize image paths\nfull_mammo_dict = dict()\ncropped_images_dict = dict()\nroi_img_dict = dict()\n\nfor dicom in full_mammo:\n    key = dicom.split(\"/\")[4]\n    full_mammo_dict[key] = dicom\nfor dicom in cropped_images:\n    key = dicom.split(\"/\")[4]\n    cropped_images_dict[key] = dicom\nfor dicom in roi_img:\n    key = dicom.split(\"/\")[4]\n    roi_img[key] = dicom\n\n# view keys\nnext(iter((full_mammo_dict.items())))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Mass Dataset","metadata":{}},{"cell_type":"code","source":"# load the mass dataset\nmass_train = pd.read_csv('/kaggle/input/cbis-ddsm-breast-cancer-image-dataset/csv/mass_case_description_train_set.csv')\nmass_test = pd.read_csv('/kaggle/input/cbis-ddsm-breast-cancer-image-dataset/csv/mass_case_description_test_set.csv')\n\nmass_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fix image paths\ndef fix_image_path(data):\n    \"\"\"correct dicom paths to correct image paths\"\"\"\n    for index, img in enumerate(data.values):\n        img_name = img[11].split(\"/\")[2]\n        data.iloc[index,11] = full_mammo_dict[img_name]\n        img_name = img[12].split(\"/\")[2]\n        data.iloc[index,12] = cropped_images_dict[img_name]\n        \n# apply to datasets\nfix_image_path(mass_train)\nfix_image_path(mass_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check unique values in pathology column\nmass_train.pathology.unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mass_train.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# rename columns\nmass_train = mass_train.rename(columns={'left or right breast': 'left_or_right_breast',\n                                           'image view': 'image_view',\n                                           'abnormality id': 'abnormality_id',\n                                           'abnormality type': 'abnormality_type',\n                                           'mass shape': 'mass_shape',\n                                           'mass margins': 'mass_margins',\n                                           'image file path': 'image_file_path',\n                                           'cropped image file path': 'cropped_image_file_path',\n                                           'ROI mask file path': 'ROI_mask_file_path'})\n\nmass_train.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check for null values\nmass_train.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fill in missing values using the backwards fill method\nmass_train['mass_shape'] = mass_train['mass_shape'].fillna(method='bfill')\nmass_train['mass_margins'] = mass_train['mass_margins'].fillna(method='bfill')\n\n#check null values\nmass_train.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# quantitative summary of features\nmass_train.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# view mass_test\nmass_test.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check datasets shape\nprint(f'Shape of mass_train: {mass_train.shape}')\nprint(f'Shape of mass_test: {mass_test.shape}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mass_test.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check for column names in mass_test\nprint(mass_test.columns)\nprint('\\n')\n# rename columns\nmass_test = mass_test.rename(columns={'left or right breast': 'left_or_right_breast',\n                                           'image view': 'image_view',\n                                           'abnormality id': 'abnormality_id',\n                                           'abnormality type': 'abnormality_type',\n                                           'mass shape': 'mass_shape',\n                                           'mass margins': 'mass_margins',\n                                           'image file path': 'image_file_path',\n                                           'cropped image file path': 'cropped_image_file_path',\n                                           'ROI mask file path': 'ROI_mask_file_path'})\n\n# view renamed columns\nmass_test.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fill in missing values using the backwards fill method\nmass_test['mass_margins'] = mass_test['mass_margins'].fillna(method='bfill')\n\n#check null values\nmass_test.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualizations","metadata":{}},{"cell_type":"code","source":"# pathology distributions\nvalue = mass_train['pathology'].value_counts()\nplt.figure(figsize=(8,6))\n\nplt.pie(value, labels=value.index, autopct='%1.1f%%')\nplt.title('Breast Cancer Mass Types', fontsize=14)\nplt.savefig('/kaggle/working/pathology_distributions_red.png')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# examine breast assessment types\nplt.figure(figsize=(8,6))\nsns.countplot(mass_train, y='assessment', hue='pathology', palette='viridis')\nplt.title('Breast Cancer Assessment\\n\\n 0: Undetermined || 1: Well Differentiated\\n2: Moderately differentiated || 3: Poorly DIfferentiated\\n4-5: Undifferentiated', \n          fontsize=12)\nplt.ylabel('Assessment Grade')\nplt.xlabel('Count')\nplt.savefig('/kaggle/working/breast_assessment_red.png')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# examine cancer subtlety\nplt.figure(figsize=(8,6))\nsns.countplot(mass_train, x='subtlety', palette='viridis')\nplt.title('Breast Cancer Mass Subtlety', fontsize=12)\nplt.xlabel('Subtlety Grade')\nplt.ylabel('Count')\nplt.savefig('/kaggle/working/cancer_subtlety_red.png')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# view breast mass shape distribution against pathology\nplt.figure(figsize=(8,6))\n\nsns.countplot(mass_train, x='mass_shape', hue='pathology')\nplt.title('Mass Shape Distribution by Pathology', fontsize=14)\nplt.xlabel('Mass Shape')\nplt.xticks(rotation=30, ha='right')\nplt.ylabel('Pathology Count')\nplt.legend()\nplt.savefig('/kaggle/working/mass_pathology_red.png')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# breast density against pathology\nplt.figure(figsize=(8,6))\n\nsns.countplot(mass_train, x='breast_density', hue='pathology')\nplt.title('Breast Density vs Pathology\\n\\n1: fatty || 2: Scattered Fibroglandular Density\\n3: Heterogenously Dense || 4: Extremely Dense',\n          fontsize=14)\nplt.xlabel('Density Grades')\nplt.ylabel('Count')\nplt.legend()\nplt.savefig('/kaggle/working/density_pathology_red.png')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display some images\nimport matplotlib.image as mpimg\n\n# create function to display images\ndef display_images(column, number):\n    \"\"\"displays images in dataset\"\"\"\n    # create figure and axes\n    number_to_visualize = number\n    rows = 1\n    cols = number_to_visualize\n    fig, axes = plt.subplots(rows, cols, figsize=(15, 5))\n    \n    # Loop through rows and display images\n    for index, row in mass_train.head(number_to_visualize).iterrows():\n        image_path = row[column]\n        image = mpimg.imread(image_path)\n        ax = axes[index]\n        ax.imshow(image, cmap='gray')\n        ax.set_title(f\"{row['pathology']}\")\n        ax.axis('off')\n    plt.tight_layout()\n    plt.show()\n\nprint('Full Mammograms:\\n')\ndisplay_images('image_file_path', 5)\nprint('Cropped Mammograms:\\n')\ndisplay_images('cropped_image_file_path', 5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing of Images","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport cv2\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.utils import to_categorical\n\ndef image_processor(image_path, target_size):\n    \"\"\"Preprocess images for CNN model\"\"\"\n    absolute_image_path = os.path.abspath(image_path)\n    image = cv2.imread(absolute_image_path)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    image = cv2.resize(image, (target_size[1], target_size[0]))\n    image_array = image / 255.0\n    return image_array\n\n# Merge datasets\nfull_mass = pd.concat([mass_train, mass_test], axis=0)\n\n# Define the target size\ntarget_size = (224, 224, 3)\n\n# Apply preprocessor to train data\nfull_mass['processed_images'] = full_mass['image_file_path'].apply(lambda x: image_processor(x, target_size))\n\n# Create a binary mapper\nclass_mapper = {'MALIGNANT': 1, 'BENIGN': 0, 'BENIGN_WITHOUT_CALLBACK': 0} \n\n# Convert the processed_images column to an array\nX_resized = np.array(full_mass['processed_images'].tolist())\n\n# Apply class mapper to pathology column\nfull_mass['labels'] = full_mass['pathology'].replace(class_mapper)\n\n# Check the number of classes\nnum_classes = len(full_mass['labels'].unique())\n\n# Split data into train, test, and validation sets (70, 20, 10)\nX_train, X_temp, y_train, y_temp = train_test_split(X_resized, full_mass['labels'].values, test_size=0.3, random_state=42)\nX_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.33, random_state=42)\n\n# Convert integer labels to one-hot encoded labels\ny_train = to_categorical(y_train, num_classes)\ny_test = to_categorical(y_test, num_classes)\ny_val = to_categorical(y_val, num_classes)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CNN Architecture","metadata":{}},{"cell_type":"code","source":"# Import necessary TensorFlow libraries\nimport necessary tensorflow libraries\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.utils import plot_model\n\n# Augment data\ntrain_datagen = ImageDataGenerator(rotation_range=40, \n                                   width_shift_range=0.2, \n                                   height_shift_range=0.2, \n                                   shear_range=0.2, \n                                   zoom_range=0.2, \n                                   horizontal_flip=True, \n                                   fill_mode='nearest'\n                                  )\n\n# apply augmentation to training data\ntrain_data_augmented = train_datagen.flow(X_train, y_train, batch_size=16)\n\n# instantiate CNN model\nmodel = Sequential()\n\n# add layers\nmodel.add(Conv2D(32, (3, 3), activation='relu', \n                 input_shape=(224, 224, 3)))\nmodel.add(MaxPooling2D((2,2)))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Conv2D(64, (3,3), activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Flatten()) # flatten feature maps\nmodel.add(Dense(512, activation='relu')) # add fully connected layers\nmodel.add(Dense(num_classes, activation='softmax')) # output layer\n\n# compile model\nmodel.compile(loss='binary_crossentropy', \n              optimizer=Adam(lr=0.0001), \n              metrics=['accuracy'])\n\n# train model\nhistory = model.fit(train_data_augmented, \n                    epochs=20, \n                    validation_data=(X_val, y_val), \n                   )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model summary\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluation","metadata":{}},{"cell_type":"code","source":"model.evaluate(X_test, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Classification Report","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\n\n# create labels for confusion matrix\ncm_labels = ['MALIGNANT', 'BENIGN']\n\n# obtain predictions\ny_pred_test = model.predict(X_test)\ny_pred_train = model.predict(X_train)\n\n# convert predicted probabilities to class predictions\ny_pred_classes_test = np.argmax(y_pred_test, axis=1)\ny_pred_classes_train = np.argmax(y_pred_train, axis=1)\n\n# Assuming y_test and y_val are in binary format (0 or 1)\ny_true_classes_test = np.argmax(y_test, axis=1)\ny_true_classes_train = np.argmax(y_train, axis=1)\n\n# generate classification reports for test and val sets\ntest_report = classification_report(y_true_classes_test, y_pred_classes_test, target_names=cm_labels)\ntrain_report = classification_report(y_true_classes_train, y_pred_classes_train, target_names=cm_labels)\n\n# generate confusion matrices for test and validation sets\ntest_cm = confusion_matrix(y_true_classes_test, y_pred_classes_test)\ntrain_cm = confusion_matrix(y_true_classes_train, y_pred_classes_train)\n\n# create function to print confusion matrix\ndef plot_confusion_matrix(cm, labels, title):\n    \"\"\"plots a normalized confusion matrix as a heatmap.\"\"\"\n    # Calculate row sums\n    row_sums = cm.sum(axis=1, keepdims=True)\n    # Normalize confusion matrix\n    normalized_cm = cm / row_sums\n\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(normalized_cm, annot=True, fmt='.2%', cmap='Blues', cbar=False,\n                xticklabels=labels, yticklabels=labels)\n    plt.title(title, fontsize=14)\n    plt.xlabel('Predicted')\n    plt.ylabel('True')\n    plt.show()\n\n# print Train and Test reports and matrices\nprint(f\"Train Set Classification report:\\n {train_report}\\n\")\nplot_confusion_matrix(train_cm, cm_labels, 'Train Set Confusion Matrix')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Test Set Classification report:\\n {test_report}\\n\")\nplot_confusion_matrix(test_cm, cm_labels, 'Test Set Confusion Matrix')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ROC_AUC Curves","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import roc_curve, auc\n\n# Use the trained model to predict probabilities for the test set\ny_pred_prob = model.predict(test_dataset)\n\n# Calculate the ROC curve\nfpr, tpr, thresholds = roc_curve(y_test[:, 1], y_pred_prob[:, 1])\nroc_auc = auc(fpr, tpr)\n\n# Plot the ROC curve\nplt.figure()\nplt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic')\nplt.legend(loc='lower right')\nplt.show()\n\n# Print the AUC score\nprint(f'AUC: {roc_auc:.2f}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualizing Loss vs Epoch/Accuracy vs Epoch ","metadata":{}},{"cell_type":"code","source":"history_dict = history.history","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot training loss vs validation loss\nloss_values = history_dict['loss']\nval_loss_values = history_dict['val_loss']\nacc = history_dict['accuracy']\n\nepochs = range(1, len(acc) + 1)\n\nplt.plot(epochs, loss_values, 'b', label='Training Loss')\nplt.plot(epochs, val_loss_values, 'r', label='Validation Loss')\nplt.title('Training and Validation Loss', fontsize=12)\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n#history_df = pd.DataFrame(history.history)\n#history_df[['loss', 'val_loss']].plot()\n\n#history_df = pd.DataFrame(history.history)\n#history_df[['accuracy', 'val_accuracy']].plot()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot training vs validation accuracy\nval_acc_values = history_dict['val_accuracy']\nacc = history_dict['accuracy']\n\nplt.plot(epochs, acc, 'b', label='Training Accuracy')\nplt.plot(epochs, val_acc_values, 'r', label='Validation Accuracy')\nplt.title('Training and Validation Accuracy', fontsize=12)\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Transfer Learning-Hyperparameter Tuning","metadata":{}},{"cell_type":"code","source":"# use VGG19\nfrom tensorflow.keras.applications import VGG19\nfrom tensorflow.keras.layers import GlobalAveragePooling2D\nfrom tensorflow.keras.callbacks import LearningRateScheduler\n\ntrain_data_aug = train_datagen.flow(X_train, y_train, batch_size=16)\n\n# Fine-tune the pretrained model\npretrained_model = VGG19(include_top=False, \n                         input_shape=(224, 224, 3), \n                         weights='imagenet')\n\n# Unfreeze the last few layers for fine-tuning\nfor layer in pretrained_model.layers[:-4]:\n    layer.trainable = False\n\n# apply Global Average Pooling to the last layer of the pretrained model\nx = GlobalAveragePooling2D()(pretrained_model.output)\n\n# add additional layers\nx = Conv2D(32, (3, 3), activation='relu')(x)\nx = MaxPooling2D((2, 2))(x)\nx = Conv2D(64, (3, 3), activation='relu')(x)\nx = MaxPooling2D((2, 2))(x)\nx = Conv2D(64, (3, 3), activation='relu')(x)\nx = MaxPooling2D((2, 2))(x)\nx = Conv2D(128, (3, 3), activation='relu')(x)\nx = MaxPooling2D((2, 2))(x)\nx = Conv2D(128, (3, 3), activation='relu')(x)\nx = MaxPooling2D((2, 2))(x)\nx = Flatten()(x)\nx = Dense(512, activation='relu')(x)\npredictions = Dense(num_classes, activation='softmax')(x)\n\n# create the updated model\nvgg_model = Model(inputs=pretrained_model.input, outputs=predictions)\n\n# define a learning rate scheduler\ndef learning_rate_scheduler(epoch): \n    if epoch < 5:\n        return 0.001\n    else:\n        return 0.0001\n\n# compile the model with a learning rate and loss function\nvgg_model.compile(optimizer=Adam(),\n                  loss='binary_crossentropy', \n                  metrics=['accuracy'])\n\n# define a learning rate scheduler callback\nlr_scheduler = LearningRateScheduler(learning_rate_scheduler)\n\n# fit the model with data augmentation and the learning rate scheduler callback\nhistory_3 = vgg_model.fit(train_data_aug, \n                          epochs=30, \n                          validation_data=(X_val, y_val), \n                          callbacks=[lr_scheduler]\n                         )\n\n# save architecture\nplot_model(vgg_model, to_file='transfer_learning-1_archictect.png', show_shapes=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model summary\nvgg_model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Classification Report: Transfer Learning","metadata":{}},{"cell_type":"code","source":"# classification report and confusion matrix\n\n#obtain predictions\ny_pred_train_vgg = vgg_model.predict(X_train)\ny_pred_test_vgg = vgg_model.predict(X_test)\n\n# convert predicted probabilities to class predictions\ny_pred_classes_test_vgg = np.argmax(y_pred_test_vgg, axis=1)\ny_pred_classes_train_vgg = np.argmax(y_pred_train_vgg, axis=1)\n\n# get true classes\ny_true_classes_train_vgg = np.argmax(y_train, axis=1)\ny_true_classes_test_vgg = np.argmax(y_test, axis=1)\n\n# generate classification report\ntest_report_vgg = classification_report(y_true_classes_test_vgg, y_pred_classes_test_vgg, target_names=cm_labels)\ntrain_report_vgg = classification_report(y_true_classes_train_vgg, y_pred_classes_train_vgg, target_names=cm_labels)\n\n# generate confusion matrix\ntest_cm_vgg = confusion_matrix(y_true_classes_test_vgg, y_pred_classes_test_vgg)\ntrain_cm_vgg = confusion_matrix(y_true_classes_train_vgg, y_pred_classes_train_vgg)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Train Set Classifcation report:\\n {train_report_vgg}\\n')\nplot_confusion_matrix(train_cm_vgg, cm_labels, 'Train Set Confusion Matrix: VGG19')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Test Set Classification report:\\n {test_report_vgg}\\n\")\nplot_confusion_matrix(test_cm_vgg, cm_labels, 'Test Set Confusion Matrix: VGG19')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ROC-AUC Curves: Transfer Learning","metadata":{}},{"cell_type":"code","source":"# ROC-AUC Curves\n\n# Use the trained model to predict probabilities for the test set\ny_pred_prob = vgg_model.predict(X_test)\n\n# Calculate the ROC curve\nfpr, tpr, thresholds = roc_curve(y_test[:, 1], y_pred_prob[:, 1])\nroc_auc = auc(fpr, tpr)\n\n# Plot the ROC curve\nplt.figure()\nplt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic-Area Under Curve (ROC-AUC)')\nplt.legend(loc='lower right')\nplt.show()\n\n# Print the AUC score\nprint(f'AUC: {roc_auc:.2f}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Epochs-Loss-Accuracy Visualization: Transfer Learning","metadata":{}},{"cell_type":"code","source":"# plot training loss vs validation loss\nloss_values = history_3_dict['loss']\nval_loss_values = history_3_dict['val_loss']\nacc = history_3_dict['accuracy']\n\nepochs = range(1, len(acc) + 1)\n\nplt.plot(epochs, loss_values, 'b', label='Training Loss')\nplt.plot(epochs, val_loss_values, 'r', label='Validation Loss')\nplt.title('Training and Validation Loss', fontsize=12)\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot training vs validation accuracy\nval_acc_values = history_3_dict['val_accuracy']\n\nplt.plot(epochs, acc, 'b', label='Training Accuracy')\nplt.plot(epochs, val_acc_values, 'r', label='Validation Accuracy')\nplt.title('Training and Validation Accuracy', fontsize=12)\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Demo","metadata":{}},{"cell_type":"code","source":"predictions = vgg_model.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\n\n# reverse class mapping\nreverse_mapper = {v:k for k, v in class_mapper.items()}\n\n# map predictions to class_names\npredicted_class_indices = np.argmax(predictions, axis=1)\npredicted_class_names = [reverse_mapper[i] for i in predicted_class_indices]\n\nground_truth_class_indices = np.argmax(y_test, axis=1)\nground_truth_class_names = [reverse_mapper[i] for i in ground_truth_class_indices]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# display predicted class_names\nnum_image_visualize = min(5, len(X_test))\n\n# create random indices to select images\nrandom_indices = random.sample(range(len(X_test)), num_image_visualize)\n\n# create subplots for images\nfig, ax = plt.subplots(1, num_image_visualize, figsize=(15, 5))\n\nfor i, idx in enumerate(random_indices):\n    ax[i].imshow(X_test[idx])\n    ax[i].set_title(f'Predicted: {predicted_class_names[idx]}', fontsize=10, color='red')\n    ax[i].text(0.5, -0.1, f'Truth: {ground_truth_class_names[idx]}', fontsize=10, ha='center', va='center', \n              transform=ax[i].transAxes, color='blue')\n    ax[i].axis('off')\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Save Model","metadata":{}}]}